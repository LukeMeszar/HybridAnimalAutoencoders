{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/atinghosh/VAE-pytorch/blob/master/VAE_CNN_BCEloss.py\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from VAE_mnist_v1 import VAE_mnist\n",
    "from VAE_CIFAR_v1 import VAE_CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "CUDA = False\n",
    "SEED = 1\n",
    "BATCH_SIZE = 128\n",
    "LOG_INTERVAL = 10\n",
    "EPOCHS = 25\n",
    "no_of_sample = 10\n",
    "DATASET = 2\n",
    "\n",
    "\n",
    "ZDIMS = 20\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PROCESSED\n",
      "loader [tensor([[[[0.4902, 0.5059, 0.5412,  ..., 0.8392, 0.8431, 0.8667],\n",
      "          [0.4000, 0.4157, 0.4549,  ..., 0.8196, 0.8275, 0.8549],\n",
      "          [0.3529, 0.3686, 0.3961,  ..., 0.8157, 0.8196, 0.8431],\n",
      "          ...,\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "         [[0.6078, 0.6157, 0.6392,  ..., 0.8588, 0.8549, 0.8667],\n",
      "          [0.5373, 0.5451, 0.5765,  ..., 0.8353, 0.8392, 0.8588],\n",
      "          [0.5137, 0.5216, 0.5373,  ..., 0.8275, 0.8314, 0.8510],\n",
      "          ...,\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "         [[0.7804, 0.7804, 0.8039,  ..., 0.8784, 0.8784, 0.9059],\n",
      "          [0.7255, 0.7255, 0.7529,  ..., 0.8745, 0.8824, 0.9059],\n",
      "          [0.7137, 0.7098, 0.7216,  ..., 0.8863, 0.8824, 0.8980],\n",
      "          ...,\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]]]]), tensor([0])]\n",
      "train_loader tensor([[[[[[0.9647, 0.9529, 0.9529,  ..., 0.9059, 0.8980, 0.9098],\n",
      "            [0.9804, 0.9686, 0.9647,  ..., 0.9137, 0.9137, 0.9255],\n",
      "            [0.9725, 0.9608, 0.9608,  ..., 0.9059, 0.9059, 0.9176],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9490, 0.9373, 0.9373,  ..., 0.9020, 0.8941, 0.9059],\n",
      "            [0.9647, 0.9529, 0.9490,  ..., 0.9098, 0.9098, 0.9216],\n",
      "            [0.9569, 0.9451, 0.9451,  ..., 0.9020, 0.9020, 0.9137],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9529, 0.9412, 0.9412,  ..., 0.9216, 0.9137, 0.9255],\n",
      "            [0.9686, 0.9569, 0.9529,  ..., 0.9294, 0.9294, 0.9412],\n",
      "            [0.9608, 0.9490, 0.9490,  ..., 0.9216, 0.9216, 0.9333],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.5294, 0.5451, 0.5647,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.5333, 0.5333, 0.5686,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.5373, 0.5294, 0.5647,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.2471, 0.2745, 0.3412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.5098, 0.5608, 0.5843,  ..., 0.5961, 0.9412, 0.9412],\n",
      "            [0.5412, 0.5569, 0.5765,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.3882, 0.3961, 0.4078,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.3961, 0.3882, 0.4118,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.3961, 0.3843, 0.4078,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.1490, 0.1725, 0.2353,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.3804, 0.4275, 0.4431,  ..., 0.4824, 0.9412, 0.9412],\n",
      "            [0.3804, 0.3961, 0.4078,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.2510, 0.2510, 0.2627,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.2588, 0.2431, 0.2667,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.2588, 0.2392, 0.2627,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.0667, 0.0863, 0.1255,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.2314, 0.2667, 0.2706,  ..., 0.4510, 0.9412, 0.9412],\n",
      "            [0.2157, 0.2235, 0.2275,  ..., 0.9412, 0.9412, 0.9412]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]]]],\n",
      "\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.2980, 0.2627, 0.2510,  ..., 0.3255, 0.3333, 0.3333],\n",
      "            [0.2902, 0.2627, 0.2588,  ..., 0.3059, 0.3176, 0.3216],\n",
      "            [0.2863, 0.2627, 0.2627,  ..., 0.2863, 0.2980, 0.3059],\n",
      "            ...,\n",
      "            [0.1255, 0.1176, 0.0941,  ..., 0.0784, 0.0902, 0.0980],\n",
      "            [0.0980, 0.1020, 0.0941,  ..., 0.0824, 0.0745, 0.0784],\n",
      "            [0.1059, 0.0902, 0.0902,  ..., 0.0784, 0.0745, 0.0745]],\n",
      "\n",
      "           [[0.3843, 0.3686, 0.3490,  ..., 0.4275, 0.4392, 0.4392],\n",
      "            [0.3765, 0.3647, 0.3490,  ..., 0.4078, 0.4196, 0.4235],\n",
      "            [0.3725, 0.3569, 0.3373,  ..., 0.3765, 0.3922, 0.4000],\n",
      "            ...,\n",
      "            [0.1686, 0.1608, 0.1373,  ..., 0.1216, 0.1333, 0.1412],\n",
      "            [0.1412, 0.1451, 0.1373,  ..., 0.1255, 0.1176, 0.1216],\n",
      "            [0.1490, 0.1373, 0.1333,  ..., 0.1216, 0.1216, 0.1216]],\n",
      "\n",
      "           [[0.4392, 0.4431, 0.4196,  ..., 0.5098, 0.5216, 0.5216],\n",
      "            [0.4353, 0.4353, 0.4078,  ..., 0.4902, 0.5020, 0.5059],\n",
      "            [0.4275, 0.4196, 0.3882,  ..., 0.4510, 0.4706, 0.4745],\n",
      "            ...,\n",
      "            [0.1765, 0.1686, 0.1451,  ..., 0.1294, 0.1412, 0.1490],\n",
      "            [0.1490, 0.1529, 0.1451,  ..., 0.1294, 0.1255, 0.1294],\n",
      "            [0.1608, 0.1451, 0.1451,  ..., 0.1294, 0.1294, 0.1294]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4314, 0.4314, 0.4314],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4353, 0.4275, 0.4314],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4314, 0.4275, 0.4314]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4706, 0.4745, 0.4745],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4706, 0.4706, 0.4745],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4706, 0.4745, 0.4784]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4392, 0.4431, 0.4431],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4431, 0.4392, 0.4431],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.4392, 0.4431, 0.4431]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]],\n",
      "\n",
      "           [[0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            ...,\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412],\n",
      "            [0.9412, 0.9412, 0.9412,  ..., 0.9412, 0.9412, 0.9412]]]]]])\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "if DATASET == 0:\n",
    "    print(\"MNIST\")\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist', train=True, download=True,transform=transforms.ToTensor()),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist', train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "elif DATASET == 1:\n",
    "    print(\"CIFAR\")\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./CIFAR10', train=True, download=True,transform=transforms.ToTensor()),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./CIFAR10', train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "    \n",
    "elif DATASET == 2:\n",
    "    print(\"CIFAR10_PROCESSED\")\n",
    "    processed_CIFAR10_data = datasets.ImageFolder(root='cifar10_processed/', transform=transforms.ToTensor())\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(processed_CIFAR10_data, batch_size=1, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for batch_ndx, sample in enumerate(loader):\n",
    "        if batch_ndx == 0:\n",
    "            print(\"loader\", sample)\n",
    "        image_list.append(sample[0])\n",
    "        label_list.append(sample[1])\n",
    "\n",
    "    train_percentage = 0.8\n",
    "    train_image_list = image_list[:int(train_percentage*len(image_list))]\n",
    "    test_image_list = image_list[int(train_percentage*len(image_list)):]\n",
    "    train_label_list = label_list[:int(train_percentage*len(label_list))]\n",
    "    test_label_list = label_list[int(train_percentage*len(label_list)):]\n",
    "\n",
    "    train_tensor_image = torch.stack(train_image_list)\n",
    "    train_tensor_label = torch.stack(train_label_list)\n",
    "    train_list = [train_tensor_image, train_tensor_label]\n",
    "    train_loader = torch.utils.data.DataLoader(train_list, batch_size=1,shuffle=True,**kwargs)\n",
    "\n",
    "\n",
    "    test_tensor_image = torch.stack(test_image_list)\n",
    "    test_tensor_label = torch.stack(test_label_list)\n",
    "    test_list = [test_tensor_image, test_tensor_label]\n",
    "    test_loader = torch.utils.data.DataLoader(test_list, batch_size=1,shuffle=True,**kwargs)\n",
    "    \n",
    "    for idx, sample in enumerate(test_loader):\n",
    "        if idx == 0:\n",
    "            print(\"train_loader\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PROCESSED\n"
     ]
    }
   ],
   "source": [
    "if DATASET == 0:\n",
    "    print(\"MNIST\")\n",
    "    model = VAE_mnist(ZDIMS, BATCH_SIZE, no_of_sample)\n",
    "elif DATASET == 1:\n",
    "    print(\"CIFAR10\")\n",
    "    model = VAE_CIFAR(ZDIMS, BATCH_SIZE, no_of_sample)\n",
    "elif DATASET == 2:\n",
    "    print(\"CIFAR10_PROCESSED\")\n",
    "    model = VAE_CIFAR(ZDIMS, BATCH_SIZE, no_of_sample)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        print(data)\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = model.loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader),\n",
    "                       loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.9f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # each data is of BATCH_SIZE (default 128) samples\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        if CUDA:\n",
    "            # make sure this lives on the GPU\n",
    "            data = data.cuda()\n",
    "\n",
    "        # we're only going to infer, so no autograd at all required: volatile=True\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += model.loss_function(recon_batch, data, mu, logvar).item()\n",
    "        if i == 0:\n",
    "            n = min(data.size(0), 8)\n",
    "            # for the first 128 batch of the epoch, show the first 8 input digits\n",
    "            # with right below them the reconstructed output digits\n",
    "            if DATASET == 0:\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.data.cpu(),\n",
    "                           './mnist/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "            elif DATASET == 1:\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(BATCH_SIZE, 3, 32, 32)[:n]])\n",
    "                save_image(comparison.data.cpu(),\n",
    "                           './CIFAR10/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e6338a7953e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a4f07e1a79ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
    "    # digits in latent space\n",
    "    sample = Variable(torch.randn(64, ZDIMS))\n",
    "    if CUDA:\n",
    "        sample = sample.cuda()\n",
    "    sample = model.decode(sample).cpu()\n",
    "\n",
    "    # save out as an 8x8 matrix of MNIST`ii digits\n",
    "    # this will give you a visual idea of how well latent space can generate things\n",
    "    # that look like digits\n",
    "    if DATASET == 0:\n",
    "        save_image(sample.data.view(64, 1, 28, 28),'./mnist/reconstruction' + str(epoch) + '.png')\n",
    "    elif DATASET == 1:\n",
    "        save_image(sample.data.view(64, 3, 32, 32),'./CIFAR10/reconstruction' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interpolation_points = 10\n",
    "sample = Variable(torch.randn(2, ZDIMS))\n",
    "first_point = sample[0]\n",
    "last_point = sample[1]\n",
    "interpolation_points_list = []\n",
    "for i in np.linspace(0,1,num_interpolation_points):\n",
    "    new_interpolation_point = (1-i)*first_point+i*last_point\n",
    "    interpolation_points_list.append(new_interpolation_point)\n",
    "\n",
    "interpolation_sample = Variable(torch.stack(interpolation_points_list))\n",
    "if CUDA:\n",
    "    interpolation_sample = interpolation_sample.cuda()\n",
    "interpolation_sample = model.decode(interpolation_sample).cpu()\n",
    "save_image(interpolation_sample.data.view(num_interpolation_points, 1, 28, 28),'./mnist/interpolation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
